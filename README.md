# LITERATURE
Words that keeps me up at night 

--------------------------------------------------------------------------------

### THE GOOD STUFF

[On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf)

[A Mathematical Theory of Communication](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)

[Steps Towards Artificial Intelligence](https://courses.csail.mit.edu/6.803/pdf/steps.pdf)

[Backpropagation](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)

[Universal Function Approximators](https://www.cs.cmu.edu/~epxing/Class/10715/reading/Kornick_et_al.pdf)

[Ilya Sutskever's PhD Thesis](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

[Backpropagation Through Time and the Brain](https://www.sciencedirect.com/science/article/pii/S0959438818302009)

[The Hutter Prize](http://prize.hutter1.net/)




--------------------------------------------------------------------------------

### RL

[Temporal Difference Learning](http://incompleteideas.net/papers/sutton-88-with-erratum.pdf)

[Policy Gradient Methods](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)

[PPO](https://arxiv.org/pdf/1707.06347.pdf)

[Generalized Advantage Estimation](https://arxiv.org/pdf/1506.02438.pdf)

[Alpha Zero (self-play)](https://arxiv.org/pdf/1712.01815.pdf)

[Alpha Go](https://www.nature.com/articles/nature16961)

[RL^2](https://arxiv.org/pdf/1611.02779.pdf)

[Relational Reinforcement Learning](https://link.springer.com/content/pdf/10.1023/a:1007694015589.pdf)

[Relational Deep Reinforcement Learning](https://arxiv.org/pdf/1806.01830.pdf)

[Alpha Star](https://www.nature.com/articles/s41586-019-1724-z)

[OpenAI Five](https://arxiv.org/pdf/1912.06680.pdf)

[Generally Capable Agents Emerge from Open Ended Play](https://arxiv.org/pdf/2107.12808.pdf)

[Human Timescale Adaptation on Open Ended Tasks](https://arxiv.org/pdf/2301.07608.pdf)

[Optimizing Agent Behavior over Long Time Scales by Transporting Value](https://arxiv.org/pdf/1810.06721.pdf)

[Continuous Adaptation via Meta-Learning in Non-stationary Environments](https://openreview.net/pdf?id=Sk2u1g-0-)

[RL Neural Turing Machines](https://arxiv.org/pdf/1505.00521.pdf)

[In Context RL with Algorithm Distillation](https://arxiv.org/pdf/2210.14215.pdf)

[A Survey of Generalization in Deep RL](https://arxiv.org/pdf/2111.09794.pdf)

[Measuring Performance in Deep RL](https://arxiv.org/pdf/1709.06560.pdf)

[Meta-Learning Survey Paper](https://arxiv.org/pdf/2004.05439.pdf)

[Learning what to Memorize](https://arxiv.org/pdf/2110.12810.pdf)

[MARL Scaling Laws](https://arxiv.org/pdf/2210.00849.pdf)

[Transformers are Sample Efficient World Models](https://arxiv.org/pdf/2209.00588.pdf)

[Accelerated Learning with Differentiable Simulation](https://arxiv.org/pdf/2204.07137.pdf)

[Grounded Language Learning](https://arxiv.org/pdf/1706.06551.pdf)

[Curriculum Learning Survey](https://arxiv.org/pdf/2101.10382.pdf)

[Collaborating with Humans without Human Data](https://arxiv.org/pdf/2110.08176.pdf)

[A Study on Dense and Sparse Rewards](https://arxiv.org/pdf/2108.03222.pdf)

[Theory of Mind as Inverse Reinforcement Learning](https://www.sciencedirect.com/science/article/pii/S2352154618302055)

[On the Role of Planning in Deep RL](https://arxiv.org/pdf/2011.04021.pdf)



--------------------------------------------------------------------------------

### ARCHITECTURES

[LSTM](https://www.bioinf.jku.at/publications/older/2604.pdf)

[ResNet](https://arxiv.org/pdf/1512.03385.pdf)

[Differentiable Neural Computer](https://www.nature.com/articles/nature20101)

[Relational Recurrent Neural Networks](https://arxiv.org/pdf/1806.01822.pdf)

[On the Properties of Neural Machine Translation (Original Attention Paper)](https://arxiv.org/pdf/1409.1259.pdf)

[Sequence to Sequence for Sets](https://arxiv.org/pdf/1511.06391.pdf)

[Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

[Transformer-XL](https://arxiv.org/pdf/1901.02860.pdf)

[GTrXL](https://arxiv.org/pdf/1910.06764.pdf)

[On Layer Norm in Transformers](https://arxiv.org/pdf/2002.04745.pdf)

[Pointer Networks](https://arxiv.org/pdf/1506.03134.pdf)

[Perciever](https://arxiv.org/pdf/2103.03206.pdf)

[Set Transformer](https://arxiv.org/pdf/1810.00825.pdf)

[Deep Sets](https://arxiv.org/pdf/1703.06114.pdf)

[The Kanerva Machine](https://arxiv.org/pdf/1804.01756.pdf)

[Neural Turing Machines](https://arxiv.org/pdf/1410.5401.pdf)

[Token Turing Machines](https://arxiv.org/pdf/2211.09119.pdf)

[Hierarchical Chunk Attention Memory](https://arxiv.org/pdf/2105.14039.pdf)

[NARX RNNs](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=548162&tag=1)

[Temporal Kernel RNNs](https://www.sciencedirect.com/science/article/pii/S0893608009002664?ref=pdf_download&fr=RR-2&rr=7e3100e1fc115935)

[DreamerV1](https://arxiv.org/pdf/1912.01603.pdf)

[DreamerV2](https://arxiv.org/pdf/2010.02193.pdf)

[DreamerV3](https://arxiv.org/pdf/2301.04104.pdf)

[GPT 1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

[GPT 2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

[GPT 3](https://arxiv.org/pdf/2005.14165.pdf)

GPT 4 paper is worthless




--------------------------------------------------------------------------------

### NEURO + MEMORY

[Continual Lifelong Learning Survey Paper](https://arxiv.org/pdf/1802.07569.pdf)

[The Prefrontal Cortex as a Meta-RL System](https://www.nature.com/articles/s41593-018-0147-8)

[Interplay of Hippocampus and Prefrontal Cortex in Memory](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3789138/)

[Dopamine Reward Prediction Error Coding](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/)

[Sleep and Memory Survey Paper](https://journals.physiology.org/doi/full/10.1152/physrev.00032.2012?rfr_dat=cr_pub++0pubmed&url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org)

[Working Memory: Looking Back and Looking Forward](https://www.nature.com/articles/nrn1201)

[Memory Formation and Long Term Retention in Humans and Animals](https://www.sciencedirect.com/science/article/pii/S0028393210001624?via%3Dihub)

[A Single Standard for Memory: The Case for Reconsolidation](https://www.nature.com/articles/nrn2590)

[Replay as Context Driven Memory Reactivation](https://www.biorxiv.org/content/10.1101/2023.03.22.533833v1.full.pdf)

[RL and Episodic Memory in Humans and Animals](https://www.annualreviews.org/doi/10.1146/annurev-psych-122414-033625)

[Dopamine Pathways Underlie the Temporal Sensitivity of Associative Learning](https://www.cell.com/cell/fulltext/S0092-8674(19)30611-7)

[Replay as a Basis for Backpropagation Through Time in the Brain](https://www.biorxiv.org/content/10.1101/2023.02.23.529770v1) 

[The Organization of Recent and Remote Memories](https://pubmed.ncbi.nlm.nih.gov/15685217/)

[Reactivation of Hippocampal Ensemble Memories During Sleep](https://pubmed.ncbi.nlm.nih.gov/8036517/)

[The Mechanisms for Pattern Completion and Separation in the Hippocampus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3812781/)







