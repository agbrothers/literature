# LITERATURE
Text that keeps me up at night - biased towards RL and Memory

--------------------------------------------------------------------------------

### THE GOOD STUFF

[On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf)

[A Mathematical Theory of Communication](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)

[The Hutter Prize](http://prize.hutter1.net/)

[Backpropagation Through Time and the Brain](https://www.sciencedirect.com/science/article/pii/S0959438818302009)

[Ilya Sutskever's PhD Thesis](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

[Steps Towards Artificial Intelligence (Minsky)](https://courses.csail.mit.edu/6.803/pdf/steps.pdf)

[Universal Function Approximators](https://en.wikipedia.org/wiki/Universal_approximation_theorem)



--------------------------------------------------------------------------------

### RL

[RL^2](https://arxiv.org/pdf/1611.02779.pdf)

[Optimizing Agent Behavior over Long Time Scales by Transporting Value](https://arxiv.org/pdf/1810.06721.pdf)

[Continuous Adaptation via Meta-Learning in Non-stationary Environments](https://openreview.net/pdf?id=Sk2u1g-0-)

[Alpha Star](https://www.nature.com/articles/s41586-019-1724-z)

[OpenAI Five](https://arxiv.org/pdf/1912.06680.pdf)

[Human Timescale Adaptation on Open Ended Tasks](https://arxiv.org/pdf/2301.07608.pdf)

[Relational Deep Reinforcement Learning](https://arxiv.org/pdf/1806.01830.pdf)

[RL Neural Turing Machines](https://arxiv.org/pdf/1505.00521.pdf)

[In Context RL with Algorithm Distillation](https://arxiv.org/pdf/2210.14215.pdf)





--------------------------------------------------------------------------------

### ARCHITECTURES

[LSTM](https://www.bioinf.jku.at/publications/older/2604.pdf)

[ResNet](https://arxiv.org/pdf/1512.03385.pdf)

[Differentiable Neural Computer](https://www.nature.com/articles/nature20101)

[Relational Recurrent Neural Networks](https://arxiv.org/pdf/1806.01822.pdf)

[On the Properties of Neural Machine Translation (Original Attention Paper)](https://arxiv.org/pdf/1409.1259.pdf)

[Sequence to Sequence for Sets](https://arxiv.org/pdf/1511.06391.pdf)

[Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

[Transformer-XL](https://arxiv.org/pdf/1901.02860.pdf)

[GTrXL](https://arxiv.org/pdf/1910.06764.pdf)

[On Layer Norm in Transformers](https://arxiv.org/pdf/2002.04745.pdf)

[Perciever](https://arxiv.org/pdf/2103.03206.pdf)

[Set Transformer](https://arxiv.org/pdf/1810.00825.pdf)

[Deep Sets](https://arxiv.org/pdf/1703.06114.pdf)

[Neural Turing Machines](https://arxiv.org/pdf/1410.5401.pdf)

[Token Turing Machines](https://arxiv.org/pdf/2211.09119.pdf)

[Hierarchical Chunk Attention Memory](https://arxiv.org/pdf/2105.14039.pdf)

[NARX RNNs](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=548162&tag=1)

[Temporal Kernel RNNs](https://www.sciencedirect.com/science/article/pii/S0893608009002664?ref=pdf_download&fr=RR-2&rr=7e3100e1fc115935)

[DreamerV2](https://arxiv.org/pdf/2010.02193.pdf)

[DreamerV3](https://arxiv.org/pdf/2301.04104.pdf)

[GPT 1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

[GPT 2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

[GPT 3](https://arxiv.org/pdf/2005.14165.pdf)

GPT 4 paper is worthless




--------------------------------------------------------------------------------

### NEURO + MEMORY

[Continual Lifelong Learning Survey Paper](https://arxiv.org/pdf/1802.07569.pdf)

[The Prefrontal Cortex as a Meta-RL System](https://www.nature.com/articles/s41593-018-0147-8)

[Interplay of Hippocampus and Prefrontal Cortex in Memory](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3789138/)

[Dopamine Reward Prediction Error Coding](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/)

[Sleep and Memory Survey Paper](https://journals.physiology.org/doi/full/10.1152/physrev.00032.2012?rfr_dat=cr_pub++0pubmed&url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org)

[Working Memory: Looking Back and Looking Forward](https://www.nature.com/articles/nrn1201)

[Memory Formation and Long Term Retention in Humans and Animals](https://www.sciencedirect.com/science/article/pii/S0028393210001624?via%3Dihub)

[A Single Standard for Memory: The Case for Reconsolidation](https://www.nature.com/articles/nrn2590)

[Replay as Context Driven Memory Reactivation](https://www.biorxiv.org/content/10.1101/2023.03.22.533833v1.full.pdf)

[RL and Episodic Memory in Humans and Animals](https://www.annualreviews.org/doi/10.1146/annurev-psych-122414-033625)

[Dopamine Pathways Underlie the Temporal Sensitivity of Associative Learning](https://www.cell.com/cell/fulltext/S0092-8674(19)30611-7)

[Replay as a Basis for Backpropagation Through Time in the Brain](https://www.biorxiv.org/content/10.1101/2023.02.23.529770v1) 

[The Organization of Recent and Remote Memories](https://pubmed.ncbi.nlm.nih.gov/15685217/)

[Reactivation of Hippocampal Ensemble Memories During Sleep](https://pubmed.ncbi.nlm.nih.gov/8036517/)

[The Mechanisms for Pattern Completion and Separation in the Hippocampus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3812781/)







